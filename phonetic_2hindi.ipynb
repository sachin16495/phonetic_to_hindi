{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the the dataset for the from system directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file = open('Annexures/eng-hindi.txt', mode='rt', encoding='utf-8')\n",
    "\n",
    "text = file.read()#.split(\"\\n\")\n",
    "\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "from pickle import dump\n",
    "from unicodedata import normalize\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset in line and seprate english and hindi part from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a loaded document into sentences\n",
    "def to_pairs(doc):\n",
    "    lines = doc.strip().split('\\n')\n",
    "    pairs = [line.split(' ') for line in  lines]\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the dataset by removing escape character "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_pairs(lines):\n",
    "    cleaned = list()\n",
    "   \n",
    "    re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "    \n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    for pair in lines:\n",
    "        clean_pair = list()\n",
    "        for line in pair:\n",
    "            \n",
    "            clean_pair.append(' '.join(line))\n",
    "        cleaned.append(clean_pair)\n",
    "    return array(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_str=to_pairs(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aadhar', 'आधार']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aadhar', 'आधार']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "enghin_pairs = clean_pairs(text_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ए ब े क स\n",
      "['a b a c u s', 'ए ब े क स']\n"
     ]
    }
   ],
   "source": [
    "print(enghin_pairs[9][1])\n",
    "print(enghin_pairs[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(enghin_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "englis=[]\n",
    "hinlis=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(enghin_pairs)):\n",
    "    englis.append(enghin_pairs[i][0])\n",
    "    hinlis.append(enghin_pairs[i][1])\n",
    "    #print('[%s] => [%s]' % (enghin_pairs[i][0], enghin_pairs[i] [1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a a d h a r'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "englis[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6999"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Test split of english and hindi part of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test=enghin_pairs[:5500],enghin_pairs[5500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainen,testen=englis[:5500],englis[5500:]\n",
    "trainhin,testhin=hinlis[:5500],hinlis[5500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b a c i n a t e', 'अ ब े स ि न े ट']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(enghin_pairs[:5500][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'आ ध ा र'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the the text using keras tokenizer on the basis of character count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the max length character from corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# max sentence length\n",
    "def max_length(lines):\n",
    "    return max(len(line.split()) for line in lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a a d h a r', 'आ ध ा र']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enghin_pairs[0:] [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['आ ध ा र',\n",
       " 'आ ज़ म ग ढ़',\n",
       " 'आ ज ़ म ा य ि श',\n",
       " 'अ ब ा ब ा',\n",
       " 'अ ब े स ि न े ट े ड',\n",
       " 'अ ब े स ि न े ट',\n",
       " 'अ ब ै क',\n",
       " 'अ ब ै क ् ट ि न ल',\n",
       " 'अ ब ै क स',\n",
       " 'ए ब े क स',\n",
       " 'अ ब द ा न',\n",
       " 'अ ब ा द ा',\n",
       " 'आ ब ा द',\n",
       " 'अ ब ै फ ़ ् ट',\n",
       " 'अ ब ल ा',\n",
       " 'ए ब ल ो न ् स',\n",
       " 'ए ब ल ो न',\n",
       " 'ऐ ब े ं प ि य र',\n",
       " 'ऐ ब े म ् प',\n",
       " 'अ ब ै ं ड न ् ड',\n",
       " 'अ ब ै ं ड न ि ं ग',\n",
       " 'अ ब ै ं ड न म े न ् ट',\n",
       " 'अ ब ै ं ड न ् स',\n",
       " 'अ ब ै ं ड न',\n",
       " 'अ ब न ी न ् द ् र न ा थ',\n",
       " 'अ व न ी न ् द ् र न ा थ',\n",
       " 'अ ब न ी',\n",
       " 'अ ब ा न',\n",
       " 'ए ब ी ए प ी',\n",
       " 'अ ब र ् ट ि क ु ल े श न',\n",
       " 'आ ब ा स ा ह े ब',\n",
       " 'अ ब े स म े ं ट',\n",
       " 'अ ब े ज़',\n",
       " 'अ ब ै श ् ड',\n",
       " 'अ ब ै श म े न ् ट',\n",
       " 'अ ब ै श',\n",
       " 'अ ब ै श ़ ् य ा',\n",
       " 'अ ब े स ि क',\n",
       " 'अ ब े ट े ब ल',\n",
       " 'अ ब े ट े ड',\n",
       " 'अ ब े ट म े ं ट',\n",
       " 'अ ब े ट ् स',\n",
       " 'अ ब े ट',\n",
       " 'अ ब े ट ि क',\n",
       " 'अ ब े ट ि ं ग',\n",
       " 'अ ब े ट ि स',\n",
       " 'अ ब े ट र',\n",
       " 'अ ब त ् त ि स',\n",
       " 'ए ब े ट ो इ र',\n",
       " 'अ ब ै क ् स ि य ा ल ि',\n",
       " 'अ ब ै क ् स ि य ा ल',\n",
       " 'अ ब ा य ा',\n",
       " 'अ ब ् ब ा ए ब ् ब ा',\n",
       " 'ए ब ् ब स ी',\n",
       " 'अ ब ् ब ा स ि द',\n",
       " 'अ ब ् ब ा स ि य ो ं',\n",
       " 'अ ब ् ब ा स ि स',\n",
       " 'अ ब ् ब ा स ी',\n",
       " 'अ ब ् ब ा स',\n",
       " 'अ ब ् ब ै ट ि य ल',\n",
       " 'ए ब ् ब ए स',\n",
       " 'ए ब ् ब ी',\n",
       " 'अ ब े',\n",
       " 'अ ब ् ब े',\n",
       " 'ए ब ् ब े',\n",
       " 'अ ब ् ब ी',\n",
       " 'ए ब ट',\n",
       " 'ए ब ् ब ट',\n",
       " 'ए ब ् र ी व ी ए ट े ड',\n",
       " 'ए ब ् र ी व ी ए ट',\n",
       " 'ए ब ् र ी व ी ए ट ि ं ग',\n",
       " 'ए ब ् र ी व ी ए श न ् स',\n",
       " 'ए ब ् र ी व ी ए श न',\n",
       " 'ए ब ् र ी व ी ए ट र',\n",
       " 'अ ब ् ब ु ल ् ल ा ह',\n",
       " 'अ ब ी ब ी ब ी',\n",
       " 'ए ब ी स ी ड ी ई ए फ़ ज ी',\n",
       " 'ए ब ी स ी ए ल',\n",
       " 'ए ब क ू ल ौ म ् ब',\n",
       " 'ए ब ी स ी ए स',\n",
       " 'ए ब ी स ी',\n",
       " 'ए ब ी स ी स ी',\n",
       " 'अ ब ् द ा ल ी',\n",
       " 'अ ब ् द ल ् ल ा ह',\n",
       " 'अ ब ् द े ल',\n",
       " 'ए ब ् ड े ल',\n",
       " 'ए ब ् ड ि य ा स',\n",
       " 'ए ब ् ड ि क े ब ल',\n",
       " 'ए ब ् ड ि क े ट े ड',\n",
       " 'ए ब ् ड ि क े ट',\n",
       " 'ए ब ् ड ि क े ट ि ं ग',\n",
       " 'ए ब ् ड ि क े श न',\n",
       " 'ए ब ् ड ि क े ट र',\n",
       " 'अ ब ड ो म े न',\n",
       " 'ए ब ड ो म ि न ल',\n",
       " 'ए ब ड ो म ि न ि स',\n",
       " 'ए ब ् ड ो म ि न ो स े ं ट े स ि स',\n",
       " 'ए ब ् ड ो म ि न ो प ् ल ा स ् ट ी',\n",
       " 'ए ब ् ड ो म ि न स न े स',\n",
       " 'ए ब ् ड ो म ि न स',\n",
       " 'ए ब ् ड ो म ि न ो व े स ि क ल',\n",
       " 'अ ब ् द ो',\n",
       " 'ए ब ् ड ् य ू स े ं स',\n",
       " 'ए ब ् ड ् य ू स े ं ट',\n",
       " 'ए ब ् ड ् य ू स',\n",
       " 'अ ब ड क ् ट े ड',\n",
       " 'अ ब ड क ् ट ि ं ग',\n",
       " 'अ ब ड क ् श न',\n",
       " 'अ ब ड क ् ट र',\n",
       " 'अ ब ड क ् ट ् स',\n",
       " 'अ ब ड क ् ट',\n",
       " 'अ ब द ु इ ल ा',\n",
       " 'अ द ु ल ह ई',\n",
       " 'अ ब ् द ु ल ् ल ा',\n",
       " 'अ ब ् द ु ल ् ल ा ह',\n",
       " 'अ ब द ु ल ् ल ा',\n",
       " 'अ ब ् द ु ल ् ल ा',\n",
       " 'अ ब ् द ु ल',\n",
       " 'अ ब ् द ु र ् र ह म ा न',\n",
       " 'अ ब ् द ु र र ह म ा न',\n",
       " 'अ ब ् द ु र',\n",
       " 'अ ब ् द ु स',\n",
       " 'ए ब ी ड ी',\n",
       " 'अ ब ी म',\n",
       " 'ऐ ब ि स ि ड े र ि य न',\n",
       " 'ऐ ब ि स ि ड े र ि य स',\n",
       " 'अ ब े द ि न',\n",
       " 'अ ब े ड',\n",
       " 'अ ब े ग',\n",
       " 'ए ब े ल ा र ् ड',\n",
       " 'अ ब े ल',\n",
       " 'अ ब े ल ि य ा न',\n",
       " 'ए ब े ल ि य न',\n",
       " 'अ ब े ल ि य ा',\n",
       " 'अ ब े ल म ो स ख स',\n",
       " 'अ ब े ल म ॉ स ् क',\n",
       " 'ए ब े ल',\n",
       " 'अ ब े न द र',\n",
       " 'अ ब े न ा द र',\n",
       " 'अ ब े न ा द े र',\n",
       " 'अ ब न ा क ी',\n",
       " 'आ ब र ् ड े र',\n",
       " 'ए ब र ड ी न',\n",
       " 'ए ब र ् ड ी न',\n",
       " 'ए ब र ् ड ो न ि य न',\n",
       " 'ए ब र ् ग ा व े न ी',\n",
       " 'ए ब र े ं स',\n",
       " 'ए ब र े ं स ी',\n",
       " 'ए ब र े ं ट',\n",
       " 'ए ब र े ट े ड',\n",
       " 'ए ब र े ट',\n",
       " 'ए ब र े श न',\n",
       " 'ए ब े र े श न',\n",
       " 'अ ब े ट े ल ि प ो प ् र ो ट ी न ी म ि य ा',\n",
       " 'अ ब े ट म े ं ट',\n",
       " 'अ ब े ट ल',\n",
       " 'अ ब े ट र',\n",
       " 'अ ब े ट ि ं ग',\n",
       " 'अ ब े ट र',\n",
       " 'अ ब े ट',\n",
       " 'अ ब े य ं स',\n",
       " 'अ ब े य ं ट',\n",
       " 'ए ब फ ै र ड',\n",
       " 'अ भ ं ग',\n",
       " 'अ भ य',\n",
       " 'आ भ ा',\n",
       " 'अ भ े द',\n",
       " 'अ भ े न र ी',\n",
       " 'अ भ ी ध न',\n",
       " 'अ भ ि ज न',\n",
       " 'अ भ ि ज ी त',\n",
       " 'अ भ ि ज ि त',\n",
       " 'अ भ ि ल ा ष ा',\n",
       " 'अ भ ि ल ा ष',\n",
       " 'अ भ ि म ा न',\n",
       " 'अ भ ि म न ् य ु',\n",
       " 'अ भ ि म न ् य ु',\n",
       " 'अ भ ि न व भ ा र त ी',\n",
       " 'अ भ ि न व ग ु प ् त ा',\n",
       " 'अ भ ि न व',\n",
       " 'अ भ ि न य',\n",
       " 'अ भ ि न े त ा',\n",
       " 'अ भ ि न े त ् र ी',\n",
       " 'अ भ ि र ू च ि',\n",
       " 'अ भ ि स म य ल ं क ा र',\n",
       " 'अ भ ि ष े क ा',\n",
       " 'अ भ ि श े ख',\n",
       " 'अ भ ि ष े क',\n",
       " 'अ भ ि य ा न',\n",
       " 'अ भ ी',\n",
       " 'अ भ म न ् य ु',\n",
       " 'अ भ ो र ् र ् ड',\n",
       " 'अ भ ो र े ं स',\n",
       " 'अ भ ो र े ं ट',\n",
       " 'अ भ ो र र ् स',\n",
       " 'अ भ ो र े र',\n",
       " 'अ भ ो र ् स',\n",
       " 'अ भ ो र',\n",
       " 'अ भ य ं क र',\n",
       " 'अ भ ् य ं क र',\n",
       " 'अ भ ् य द स ा',\n",
       " 'अ भ ् य ु द य',\n",
       " 'अ ब ि य ा',\n",
       " 'ए ब ि ड े न ् स',\n",
       " 'अ ब ा इ ड',\n",
       " 'आ ब ी ड ी न',\n",
       " 'अ ब ा इ ड ि ं ग',\n",
       " 'अ ब ि द ी न',\n",
       " 'आ ब ि द ज ा न',\n",
       " 'अ ब ि द',\n",
       " 'आ ब ि द',\n",
       " 'ए ब ि य न ् स',\n",
       " 'ए ब ि ए ं ट',\n",
       " 'ए ब ि ग ै ल',\n",
       " 'ए ब ि ल ि ट ी ज ़',\n",
       " 'ए ब ि ल ि ट ी',\n",
       " 'अ भ ि न ा श',\n",
       " 'अ भ ि न व',\n",
       " 'अ ब ी र',\n",
       " 'अ भ ि ष े क',\n",
       " 'अ ब ि त ा भ',\n",
       " 'ए ब ी व र ् ड',\n",
       " 'अ ब ् ज ा द म ि न ौ र',\n",
       " 'अ ब ् ज द',\n",
       " 'अ ब ् ज ा द',\n",
       " 'अ ब ख ा ज ि य ा',\n",
       " 'अ ब ख ़ ा ज ़ ि य ा',\n",
       " 'अ ब ल ा क',\n",
       " 'ए ब ल',\n",
       " 'ए ब ी ए म',\n",
       " 'ए ब ी ए न',\n",
       " 'अ ब ो ध',\n",
       " 'अ ब ो ह र',\n",
       " 'अ ब ो ं ग',\n",
       " 'अ ब ो र',\n",
       " 'अ ब ु ल',\n",
       " 'अ ब ा उ ट',\n",
       " 'अ ब व',\n",
       " 'अ ब ् र ा ह म ि क',\n",
       " 'अ ब ् र ा ह म ् स',\n",
       " 'अ ब ् र ा ह म',\n",
       " 'ए ब ् र ा ह म',\n",
       " 'अ ब ् र ा म ् स',\n",
       " 'अ ब ् र े स ि व ् स',\n",
       " 'अ ब ् र ि क ो स ो व',\n",
       " 'ए ब ् र ि ल',\n",
       " 'अ ब र ो',\n",
       " 'अ ब ् र ू ज़ ो',\n",
       " 'ए ब ी आ र',\n",
       " 'अ ब स ि य न',\n",
       " 'ए ब ् स ो ल ् य ू ट',\n",
       " 'ए ब ् स ् ट ् र ै क ् ट आ ई ल',\n",
       " 'ए ब े स ् ट ् र े क ् श न',\n",
       " 'ए ब ् स ् ट ् र ै क ् श न',\n",
       " 'ए ब स ् ट ् र ै क ् ट',\n",
       " 'ए ब ् स ट ् र ै क ् ट',\n",
       " 'ए ब ी ए स',\n",
       " 'अ ब ् त ा ह ी',\n",
       " 'आ ब ट ा',\n",
       " 'अ ब ु ज ा',\n",
       " 'अ ब ू ज ा',\n",
       " 'आ ब ु ज ा',\n",
       " 'अ ब ु ल ह ो ल',\n",
       " 'अ ब ु ल',\n",
       " 'आ ब ु ल',\n",
       " 'अ ब ु न ि म ा ह',\n",
       " 'अ ब ु स ा र ि य ा',\n",
       " 'ए ब ् य ू ज ़',\n",
       " 'अ ब ु',\n",
       " 'अ ब ू',\n",
       " 'अ ब य न',\n",
       " 'अ ब ी स ी न ि य ा',\n",
       " 'ए ब ि स ो क ो ट ि द े',\n",
       " 'ए ब ि स',\n",
       " 'अ क ै ड म ि य ा',\n",
       " 'अ क ै ड म ि क ल ी',\n",
       " 'अ क ै ड म ी श ी य न',\n",
       " 'अ क ै ड म ि क ् स',\n",
       " 'अ क ै ड म ि क',\n",
       " 'अ क ै ड म ी स',\n",
       " 'अ क ै ड म ी',\n",
       " 'अ क ै म ि य ा',\n",
       " 'अ क े म ् प ् र ो स े ट',\n",
       " 'अ क न थ ू र ी ड े',\n",
       " 'ए क े न ् थ स',\n",
       " 'ए क े प ् न ि य ा',\n",
       " 'ए क ै र ा ई',\n",
       " 'ए क ा र य ा',\n",
       " 'ए क ा र',\n",
       " 'अ क ा स ु स ो',\n",
       " 'ए स ी ए',\n",
       " 'ए स ी ब ी',\n",
       " 'ए क ् स े ल र े ट र ् स ा',\n",
       " 'ए क ् स े ल र े ट र ् स',\n",
       " 'ए क ् स ी ल र े ट र',\n",
       " 'ए क ् स े ल',\n",
       " 'ए क ् स े ं ट',\n",
       " 'ए क ् स े प ् ट े ं स',\n",
       " 'ए क ़ ् स े प ् ट े ं स',\n",
       " 'ए क ् स े प ् ट े ड',\n",
       " 'ए क ् स े प ् ट',\n",
       " 'ए क ् स े र ् स ा इ स र',\n",
       " 'ए क ् स े स ् स ड',\n",
       " 'ए क ् स े स े स',\n",
       " 'ए क ् स े स ि ब ि ल ि ट ी',\n",
       " 'ए क ् स े स ि ब ि ल',\n",
       " 'ए क ् स े स ि ब ि ल ि ट ी',\n",
       " 'ए क ् स स े स र ी ज़',\n",
       " 'ए क ् स े स र ी ज ़',\n",
       " 'ए क ् स े स र ् स',\n",
       " 'ए क ् स े स र',\n",
       " 'ए क ् स स े स प ॉ इ ं ट',\n",
       " 'ए क ् स े स ए क ् स',\n",
       " 'ए क ् स े स',\n",
       " 'अ च ् य ु त न',\n",
       " 'ए क ् स ी ड े ं ट ल',\n",
       " 'ए क ् स ि ड े न ् ट ् स',\n",
       " 'ए क ् स ि ड े ं ट',\n",
       " 'ए क ् स ी ड े ं ट',\n",
       " 'अ क ौ र ् ड ि ं ग',\n",
       " 'ए क ॉ र ् ड ि अ न',\n",
       " 'अ क ा उ ं ट े ं स ी',\n",
       " 'अ क ा उ ं ट े ं ट ् स',\n",
       " 'अ क ा उ ं ट े ं ट',\n",
       " 'अ क ा उ ं ट ि ं ग',\n",
       " 'अ क ा उ न ् ट ् स',\n",
       " 'अ क ा उ ं ट',\n",
       " 'अ क ा उ ं ट ् स',\n",
       " 'अ क ा उ न ् ट',\n",
       " 'अ क ा उ ं ट',\n",
       " 'अ क र ा',\n",
       " 'अ क ् र ा',\n",
       " 'ए क ् र ा',\n",
       " 'ए क ् र े ड ि ट े श न',\n",
       " 'ए क ् य ू र े ट',\n",
       " 'ए क र ् स ् ट',\n",
       " 'ए स ी ड ी',\n",
       " 'अ क े',\n",
       " 'अ स े ह',\n",
       " 'आ स े ह',\n",
       " 'ए स े ह',\n",
       " 'ए स े ल ् य ु ल र',\n",
       " 'ए स े ं ट ् र ि क',\n",
       " 'अ स े स ् त ् र ो र ि ं च स',\n",
       " 'ए स ी ई ए स',\n",
       " 'ए स ि ट े ट',\n",
       " 'ए स ि ट ि क',\n",
       " 'ए स ी ट ो न',\n",
       " 'ए स ि ट ि ल क ो ल ि न',\n",
       " 'ए स ि ट ि ल क ो ल ि न',\n",
       " 'ए स ि ट ि ल े ल े',\n",
       " 'ए स ि ट ि ल ी न',\n",
       " 'ए स',\n",
       " 'अ च ा न ् त र',\n",
       " 'अ च ा र',\n",
       " 'ए क ि य ं स',\n",
       " 'ए क ि य न',\n",
       " 'अ च ल',\n",
       " 'अ च ल ा',\n",
       " 'अ च ल ग ढ ़',\n",
       " 'अ च ल',\n",
       " 'अ च न ा क म र',\n",
       " 'अ च ा न क म ा र',\n",
       " 'अ च ा न क',\n",
       " 'अ च न क ो व ि ल',\n",
       " 'अ च ं म ् भ ि त',\n",
       " 'अ च ् च न',\n",
       " 'अ च र स',\n",
       " 'आ च ा र ् य ा स',\n",
       " 'आ च ा र ् य',\n",
       " 'अ च र',\n",
       " 'अ च ै ट ी न स',\n",
       " 'अ च ् छ ा',\n",
       " 'अ च े ब े',\n",
       " 'अ च े र े ट',\n",
       " 'अ च े र ौ न ट ि य ा',\n",
       " 'अ च ् छ ि',\n",
       " 'अ छ न े र ा',\n",
       " 'अ छ ू त',\n",
       " 'अ च ् य ु त',\n",
       " 'अ क ि ल ी ज ़',\n",
       " 'ए क ि ल ी ज़',\n",
       " 'ए क ी ल ी ज़',\n",
       " 'अ च ि ल ् ल े',\n",
       " 'अ च ि म',\n",
       " 'अ च क न',\n",
       " 'अ च ल ा',\n",
       " 'ए क ् र ो म ट ि न',\n",
       " 'अ च ् य ु त न',\n",
       " 'अ च ् य ु त ा न ं द',\n",
       " 'अ च ् य ु त ा न ं द',\n",
       " 'अ च ् य ु त',\n",
       " 'अ च ् य ु त',\n",
       " 'ए स ि ड े म ि य ा',\n",
       " 'ए स ि ड ् स',\n",
       " 'ए स ि ड',\n",
       " 'ए क र म ै न',\n",
       " 'ए स ी ए ल ए स',\n",
       " 'ए स ी ए ल',\n",
       " 'अ क ो ं क ा ग ु आ',\n",
       " 'ए क ो र ् न',\n",
       " 'अ क ू स ् ट ि क ् स',\n",
       " 'अ क ू स ् ट ि क',\n",
       " 'ए स ी प ी आ ई',\n",
       " 'ए स ी प ी',\n",
       " 'अ क ् व े ं ट ् स',\n",
       " 'ए क ् र े स',\n",
       " 'ए क ड़',\n",
       " 'ए क र',\n",
       " 'ए क ् र े',\n",
       " 'ए स ी आ र ई',\n",
       " 'ए क ् र ो ब े ट',\n",
       " 'ए क ् र ो ब ै ट',\n",
       " 'ए क ् र ो न ि म',\n",
       " 'ए क ् र ो र ी ड',\n",
       " 'ए क ् र ि ल ा म ा इ ड',\n",
       " 'ए क ् र ि ल ि क',\n",
       " 'ए स ी आ र',\n",
       " 'अ क ् स ब ा ए ई न',\n",
       " 'ए स ी ए स स ी',\n",
       " 'ए स ी ट ी ए च',\n",
       " 'ए क ् ट ि य स',\n",
       " 'ए क ् ट ी न ि य म',\n",
       " 'ए क ् ट ी न ो न ् स',\n",
       " 'ए क ् श न',\n",
       " 'ए क ् ट ि व े श न',\n",
       " 'ए क ् ट ि व',\n",
       " 'ए क ् ट ि व ि ज़ न',\n",
       " 'ए क ् ट ि व ि ट ी ज़',\n",
       " 'ए क ् ट ि व ि ट ी',\n",
       " 'ए क ् ट र ् स',\n",
       " 'ए क ् ट र',\n",
       " 'ए क ् ट ् स',\n",
       " 'ए क ् च ु अ ल ी',\n",
       " 'ए क ् ट ु अ ल ी',\n",
       " 'ए क ् च ु अ ल',\n",
       " 'ए क ् च ु ए ट र ् स',\n",
       " 'ए क ् ट',\n",
       " 'ए क ़ ् ट',\n",
       " 'ए स ी ट ी',\n",
       " 'ए क ् य ू म े न',\n",
       " 'ए क ् य ू प ् र े श र',\n",
       " 'ए क ् य ू प ं क ् च र',\n",
       " 'ए स ी य ू ए स',\n",
       " 'अ क ् य ू ट',\n",
       " 'ए क ् य ू ट',\n",
       " 'ए स ी य ू',\n",
       " 'ए क ् व र ् थ',\n",
       " 'ए क ़ ् व र ् थ',\n",
       " 'अ च ् य ु त ा न न ् द',\n",
       " 'अ द ा ल त',\n",
       " 'अ द ब ी',\n",
       " 'अ ड क',\n",
       " 'अ ड ा क',\n",
       " 'अ द क',\n",
       " 'अ द ा ल ज',\n",
       " 'अ द ा ल त ् स',\n",
       " 'अ द ा ल त',\n",
       " 'आ द म ी',\n",
       " 'आ द म ज ी',\n",
       " \"ए ड म ' स\",\n",
       " 'ए ड म ् स',\n",
       " 'आ द म',\n",
       " 'ए ड म',\n",
       " 'अ द ा न ी',\n",
       " 'अ द न स ो न ि य ा',\n",
       " 'अ द न',\n",
       " 'ए ड े प ् ट र ् स',\n",
       " 'ए ड े प ् ट र',\n",
       " 'अ ड ै प ् ट ि व',\n",
       " 'अ ड ै प ् ट र',\n",
       " 'आ द र न ा',\n",
       " 'अ द र क र',\n",
       " 'आ द र ् श ा',\n",
       " 'आ द र ् श',\n",
       " 'अ द र ् व व े द',\n",
       " 'अ द र',\n",
       " 'अ ड ौ ल त ् स',\n",
       " 'अ ड ा',\n",
       " 'अ द ा',\n",
       " 'आ द ा',\n",
       " 'ए ड ी ए',\n",
       " 'अ द ् भ ू त ा न न ् द',\n",
       " 'ए ड ी ब ी',\n",
       " 'ए ड ी स ी प ी ए म',\n",
       " 'ए ड ी स ी',\n",
       " 'ए ड े ड',\n",
       " 'ए ड ि न',\n",
       " 'ए ड ि स अ ब ा ब ा',\n",
       " 'ए ड ि स न',\n",
       " 'ए ड ि स',\n",
       " 'ए ड ि श न ल',\n",
       " 'ए ड ी श न ल',\n",
       " 'ए ड ि श न',\n",
       " 'ए ड ी श न',\n",
       " 'अ द ि त ि',\n",
       " 'ए ड ् र े स े स',\n",
       " 'ए ड ् र े स ि ं ग',\n",
       " 'ए ड ् र े स',\n",
       " 'ए ड ् ड',\n",
       " 'ऐ ड',\n",
       " 'ए ड ि ल े ड',\n",
       " 'अ ड े ल',\n",
       " 'ए ड ी ल ा य',\n",
       " 'ए ड े ल ् ल े',\n",
       " 'ए ड ी न ा इ न',\n",
       " 'ए ड ी न ो स ि न',\n",
       " 'ए ड ि न ो व ा य र स',\n",
       " 'ए ड े न',\n",
       " 'अ ड े प ् ट',\n",
       " 'ए ड र ् म ि न',\n",
       " 'ए ड फ ़ ै म',\n",
       " 'ए ड ी ए फ स ी ए स',\n",
       " 'ए ड ी ए फ',\n",
       " 'अ ढ ़ ा ई',\n",
       " 'अ ध म',\n",
       " 'अ ध र ा',\n",
       " 'अ ध ा',\n",
       " 'आ ध ा',\n",
       " 'अ द ् भ ु त',\n",
       " 'ए ड ी ए च ड ी',\n",
       " 'अ ढ ी स ि व',\n",
       " 'अ ध ि क ा ं श',\n",
       " 'अ ध ि क ा र ी',\n",
       " 'अ ध ि क',\n",
       " 'अ ध ि म ा स',\n",
       " 'अ ध ि न क ा श',\n",
       " 'अ ध ि प त ि',\n",
       " 'अ ध ि र ा ई',\n",
       " 'अ ध ि र ा ज',\n",
       " 'अ ध ि ष थ ा न स',\n",
       " 'अ ध ि ष ् ठ ा न ा स',\n",
       " 'अ ध ि ष ् ठ ा न',\n",
       " 'अ ध ि श ् त ा त ् र ी',\n",
       " 'अ ध ि व ा स',\n",
       " 'अ ध ि व ृ ष न',\n",
       " 'आ ध ी',\n",
       " 'अ ध ् व र ् य ु ग न',\n",
       " 'अ ध ् व र ् य ु ग ण',\n",
       " 'अ ध ् व र ् य ु ग ण',\n",
       " 'अ ध व ा ट े',\n",
       " 'अ ध ् य ा त ् म',\n",
       " 'अ ध ् य ा त ् म क',\n",
       " 'अ द ि आ ल ा',\n",
       " 'अ द ि ब ा स ि स',\n",
       " 'अ द ि ब',\n",
       " 'ए ड ि ड ा स',\n",
       " 'आ द ि ग ै म ा न',\n",
       " 'अ ड ि ग ल',\n",
       " 'अ ड ि ग',\n",
       " 'आ द ि क व ि',\n",
       " 'अ द ि ल ा ब ा द',\n",
       " 'अ द ी ल ा ब ा द',\n",
       " 'आ द ि ल ा ब ा द',\n",
       " 'आ द ि ल ् स',\n",
       " 'आ द ि ल',\n",
       " 'आ द ि म ज ा त ि',\n",
       " 'आ द ि म',\n",
       " 'आ द ि न ा थ',\n",
       " 'आ द ि प र ् व',\n",
       " 'आ द ि प ा थ',\n",
       " 'ए ड ि प ो स ा इ ट',\n",
       " 'ए ड ि प ो ज़',\n",
       " 'आ द ी प ु र',\n",
       " 'आ द ि त ल स',\n",
       " 'आ द ि त ल ा',\n",
       " 'आ द ि त ा ल',\n",
       " 'आ द ि त ा ल ा',\n",
       " 'अ द ि त ि',\n",
       " 'आ द ि त ् य ह ृ द य म ्',\n",
       " 'आ द ि त ् य',\n",
       " 'ए ड ि य म',\n",
       " 'आ द ि व र ा ह',\n",
       " 'आ द ि व ा स ी स',\n",
       " 'आ द ि व ा स ी',\n",
       " 'अ द ि व ा क न',\n",
       " 'अ द ि',\n",
       " 'आ द ि',\n",
       " 'अ ड ज स ् ट े ड',\n",
       " 'अ ड ज स ् ट म े ं ट ् स',\n",
       " 'अ ड ज स ् ट म े ं ट',\n",
       " 'ए ड ज स ् ट म े ं ट',\n",
       " 'ए ड ् ज े स ् ट म े ं ट',\n",
       " 'अ ड ज स ् ट',\n",
       " 'ए ड ज स ् ट',\n",
       " 'अ ड ज ु ट े ं ट ् स',\n",
       " 'अ ड ज ु ट े ं ट',\n",
       " 'ए ड ज ु ट े ं ट',\n",
       " 'ए ड ल र',\n",
       " 'ए ड ी ए म ब ी',\n",
       " 'ए ड ी ए म ड ी',\n",
       " 'ए ड म ि न ि स ् ट ् र े श न',\n",
       " 'ए ड म ि न ि स ् ट ् र े ट ि व',\n",
       " 'ए ड म ि न ि स ् ट ् र े ट र',\n",
       " 'ए म ि न ि स ् ट ् र ि व ि य ा',\n",
       " 'ए ड म ि न ् स',\n",
       " 'ए ड म ि न',\n",
       " 'ए ड म ि र ल',\n",
       " 'ए ड म ि श ं स',\n",
       " 'ए ड म ि श न',\n",
       " 'ए ड म ि ट',\n",
       " 'ए ड ी ए म',\n",
       " 'अ द न ा न',\n",
       " \"अ ड ो ब ' स\",\n",
       " 'अ ड ो ब',\n",
       " 'अ ड ो ब ी',\n",
       " 'अ ड ो ब े',\n",
       " 'अ ड ॉ ल े स ै ं ट ् स',\n",
       " 'अ ड ा ल ् फ',\n",
       " 'ए ड ॉ ल ् फ',\n",
       " 'ए ड ॉ म ् स',\n",
       " 'आ द ो न ी',\n",
       " 'अ ड ू र',\n",
       " 'अ द ू र',\n",
       " 'ए ड ी प ी स ी ए म',\n",
       " 'ए ड ी प ी',\n",
       " 'ए ड ् र े म ा',\n",
       " 'अ ड ् र ी न ल ी न',\n",
       " 'ए ड ् र ी न ल ी न',\n",
       " 'अ ड ् र ि न ल',\n",
       " 'ए ड ् र ि न ल',\n",
       " 'अ ड ् र ी न ो क ा र ् ट ी क ल',\n",
       " 'ए ड ् र ि य न',\n",
       " 'ए ड ् र ि य ा ट ि क',\n",
       " 'अ द ् र ि ध र न',\n",
       " 'ए ड ी आ र ए स',\n",
       " 'ए ड ी आ र',\n",
       " 'ए ड ् स े ं स',\n",
       " 'ए ड ी ए स आ ई',\n",
       " 'ए ड ी ए स ए ल',\n",
       " 'ए ड ी ए स ए म',\n",
       " 'ए ड ी ए स',\n",
       " 'ए ड ी ट ी',\n",
       " 'अ ड ल ् ट ् स',\n",
       " 'अ ड ल ् ट',\n",
       " 'अ द ु ल ् य द े ज',\n",
       " 'अ द ् व ै त म ्',\n",
       " 'अ द ् व ै त',\n",
       " 'अ द ् व ै त ा',\n",
       " 'अ द ् व ै त',\n",
       " 'अ ड व ा ं स ् ड',\n",
       " 'ए ड व ा ं स ् ड',\n",
       " 'ए ड व ा न ् स ् म े न ् ट',\n",
       " 'ए ड व ा ं स म े ं ट',\n",
       " 'ए ड व ा न ् स े स',\n",
       " 'अ ड व ा ं स',\n",
       " 'ए ड व ा न ् स',\n",
       " 'आ ड व ा न ी ज ी',\n",
       " 'आ ड व ा ण ी',\n",
       " 'आ ड व ा न ी',\n",
       " 'अ ड व र ु ग न ा',\n",
       " 'ए ड ् व ै न ् च र',\n",
       " 'ए ड ् व र ग े म',\n",
       " 'ए ड व ा इ स',\n",
       " 'ए ड ् व ा ई स',\n",
       " 'ए ड व ा इ ज़ र ् स',\n",
       " 'ए ड व ा इ ज़ र ी',\n",
       " 'ए ड व ो क े ट ् स',\n",
       " 'ए ड व ो क े ट',\n",
       " 'अ द ् व ै त',\n",
       " 'ए ड व े य र',\n",
       " 'आ द ् य ा र',\n",
       " 'आ द ् य ा त न',\n",
       " 'आ द ् य ा',\n",
       " 'अ द ि ग ि य ा',\n",
       " 'अ द ि त ु म',\n",
       " 'ए ड ि स',\n",
       " 'ए ड ी ज',\n",
       " 'ए ज ी ए न',\n",
       " 'ए ई ग ल',\n",
       " 'इ ज ी प ् ट ि आ क ा',\n",
       " 'ए ज ि प ् ट ा इ',\n",
       " 'ए इ य ा श म ा प ा न',\n",
       " 'ए य ो ल ी स',\n",
       " 'ए ई प ी स ी',\n",
       " 'ए र े ट े ड',\n",
       " 'ए र े श न',\n",
       " 'ए र े ट र',\n",
       " 'ए य र ो ब ि क',\n",
       " 'ए य र ो ड ् र ो म ् स',\n",
       " 'ए य र ो ड ् र ो म',\n",
       " 'ए य र ो ड ा ई न ै म ि क',\n",
       " 'ए य र ो इ ं ज ि न',\n",
       " 'ए य र ो फ ़ ् ल ो ट',\n",
       " 'ए य र ो फ ॉ इ ल ् स',\n",
       " 'ए य र ो ज े न र े ट र',\n",
       " 'ए य र ो न ॉ ट ि क ल',\n",
       " 'ए य र ो स ् म ि थ',\n",
       " 'ए य र ो स ौ ल ् स',\n",
       " 'ए य र ो स ौ ल',\n",
       " 'ए य र ो स ौ ल ् स',\n",
       " 'ए अ र ो स ् प े स',\n",
       " 'ए य र ो स ् प े स',\n",
       " 'ए र ो स ् प े स',\n",
       " 'ए र ो स ् ट े ट',\n",
       " 'ए र ो स ् व ि त',\n",
       " 'ए य र ो',\n",
       " 'ए श ा य ल स',\n",
       " 'ए स ॉ प',\n",
       " 'ए ई ए स',\n",
       " 'ए त ब ा र',\n",
       " 'अ फ ़ ा द ी',\n",
       " 'अ फ ़ ा न स ी',\n",
       " 'अ फ ़ ा र े न ् स ि स',\n",
       " 'अ फ ा र ् स',\n",
       " 'अ फ ा र ी',\n",
       " 'अ फ ़ ा र',\n",
       " 'ए ए फ ़ ए',\n",
       " 'ए ए फ स ी',\n",
       " 'ए ए फ ई',\n",
       " 'अ फ े य र ् स',\n",
       " 'अ फ ् फ ा न',\n",
       " 'ए ए फ ए फ ए आ र ए म',\n",
       " 'अ फ े क ् ट',\n",
       " 'अ फ ् फ न प ि न ् स ् च र',\n",
       " 'ए फ र े ं ट',\n",
       " 'अ फ ़ ी ड े व ि ट ्',\n",
       " 'ए फ़ ि ड े व ि ट',\n",
       " 'ए फ ़ ी ड े व ि ट ्',\n",
       " 'ए फ ़ ि न ि ट ी',\n",
       " 'ए फ ् ल े क',\n",
       " 'अ फ ़ ग ा न',\n",
       " 'अ फ ़ ग ा न ि स ् त ा न',\n",
       " 'अ फ ़ ग ा न ि स ् थ ा न',\n",
       " 'अ फ ़ ग न',\n",
       " 'अ फ ़ ग ा न',\n",
       " 'अ फ ़ घ न ा इ स ् ड',\n",
       " 'अ फ ़ ग ा न ि स ् त ा न ी',\n",
       " \"अ फ ़ ग ा न ि स ् त ा न ' स\",\n",
       " 'अ फ ़ ग ा न ि स ् त ा न',\n",
       " 'अ फ ़ घ न ी',\n",
       " 'अ फ ़ घ ा न ि स ् त ा न',\n",
       " 'अ फ ़ घ ा न ी',\n",
       " 'अ फ ़ ग ा न ् स',\n",
       " 'अ फ ़ घ न ् स',\n",
       " 'अ फ ़ घ ा न ् स',\n",
       " 'अ फ ़ ग ़ ा न',\n",
       " 'अ फ ़ घ न',\n",
       " 'अ फ ़ घ ा न',\n",
       " 'ए ए फ ज ी आ ई ए स',\n",
       " 'अ फ ज ल',\n",
       " 'ए ए फ ए म',\n",
       " 'ए फ ए म',\n",
       " 'ए ए फ ए न ए च ब ी',\n",
       " 'ए ए फ ए न',\n",
       " 'अ फ ़ ् प ा क',\n",
       " 'ए ए फ प ी',\n",
       " 'अ फ ़ ् र ी क ा न ा',\n",
       " 'अ फ ़ ् र ि क ा न ि स',\n",
       " 'अ फ ़ ् र ी क ा न ् स',\n",
       " 'ए फ ़ ् र ी क न ् स',\n",
       " 'अ फ ़ ् र ी क न',\n",
       " \"ए फ ़ ् र ी क ा ' स\",\n",
       " 'अ फ र ी क ा',\n",
       " 'अ फ ़ र ी क ा',\n",
       " 'अ फ ़ ् र ी क ा',\n",
       " 'अ फ ़ र ी द ी स',\n",
       " \"अ फ ़ र ी द ी ' स\",\n",
       " 'अ फ ़ र ी द ी',\n",
       " 'अ फ ् र ी द ी',\n",
       " 'अ फ ् र ी क ा ं स',\n",
       " 'ए फ ़ ् र ी क ा ं स',\n",
       " 'ए फ ् र ो',\n",
       " 'अ फ ़ स ा न ा',\n",
       " 'अ फ ़ स र',\n",
       " 'अ फ ़ स ो स',\n",
       " 'आ फ ् ट र ल ा इ फ',\n",
       " 'आ फ ् ट र न ू न',\n",
       " 'आ फ ् ट र स ् ट े प',\n",
       " 'आ फ ् ट र',\n",
       " 'अ फ ज ़ ल',\n",
       " 'अ ग े ं स ् ट',\n",
       " 'अ ग ै न',\n",
       " 'अ ग म स',\n",
       " 'आ ग म स',\n",
       " 'आ ग म ा स',\n",
       " 'अ ग म ा',\n",
       " 'आ ग म',\n",
       " 'अ ग ा म े म न न',\n",
       " 'अ ग म',\n",
       " 'अ ग म',\n",
       " 'आ ग न ् त ु क',\n",
       " 'अ ग ् र त ् व च ा',\n",
       " 'अ ग ा र ा',\n",
       " 'अ ग र ि य ा',\n",
       " 'आ ग र क र',\n",
       " 'अ ग र त ल ा',\n",
       " 'अ ग र ् व स र ् व म ं ग क ा',\n",
       " 'अ ग र व ा ल ् स',\n",
       " 'अ ग ् र व ा ल',\n",
       " 'अ ग र',\n",
       " 'अ ग ा र',\n",
       " 'ए ग ा र',\n",
       " 'अ ग स ् थ ् य म ल ा इ',\n",
       " 'अ ग स ् थ ् य',\n",
       " 'अ ग स ् त य त ी र ् थ',\n",
       " 'अ ग स ् त ् य त ी र ् थ',\n",
       " 'अ ग स ् त ् य',\n",
       " 'अ ग ा थ ा',\n",
       " 'अ ग ा थ ी',\n",
       " 'अ ग ट ् ट ी',\n",
       " 'अ ग त ् त ी',\n",
       " 'अ ग ा व े',\n",
       " 'अ ग ा',\n",
       " 'आ ग ा',\n",
       " 'ए ज े ड',\n",
       " 'अ ग े ह ा न न ् द',\n",
       " 'ए ज े ं स ी ज़',\n",
       " 'ए ज े न ् स ी',\n",
       " 'ए ज े ं स ी',\n",
       " 'ए ज े ण ् ड ा स',\n",
       " 'अ ज े ं ड ा',\n",
       " 'ए ज े ण ् ड ा',\n",
       " 'ए ज े ण ् ड ा',\n",
       " 'ए ज े न ् ड ा',\n",
       " 'ए ज े ं ड ा',\n",
       " 'ए ज े न ् ड म',\n",
       " 'ए ज े ं स ट ् स',\n",
       " 'ए ज े न ् ट ् स',\n",
       " 'ए ज े ं ट ् स',\n",
       " 'ए ज े न ् ट',\n",
       " 'ए ज े ं ट',\n",
       " 'अ ग े र व ा ल',\n",
       " 'अ ग न',\n",
       " 'अ ग ् ग र व ा ल',\n",
       " 'ए ग ् र ी ग े ट र',\n",
       " 'ए ग ् र ी ग े ट ् स',\n",
       " 'ए ग ् र ी ग े श न',\n",
       " 'ए ग ् र ी ग े ट र ् स',\n",
       " 'ए ग ् र ी ग े ट र',\n",
       " 'अ ग ् ग ् र े स न',\n",
       " 'अ घ ा म े द ा ब ा द',\n",
       " 'अ घ न',\n",
       " 'आ घ न',\n",
       " 'अ घ र क र',\n",
       " 'अ घ ा',\n",
       " 'आ ग ा',\n",
       " 'अ घ ो र घ ं ट ा',\n",
       " 'अ घ ो र न ा थ',\n",
       " 'अ घ ो र े न ा थ',\n",
       " 'अ घ ो र े',\n",
       " 'अ घ ो र न ा थ',\n",
       " 'अ घ ो र प ं थ',\n",
       " 'ए ज ि ं ग',\n",
       " 'ए ज ी ट े श न',\n",
       " 'ए ज ि ट े ट र',\n",
       " 'ए ग ् ल े ट',\n",
       " 'ए ग म ा र ् क',\n",
       " 'ए ज ी ए म',\n",
       " 'अ ग ् न ि प थ',\n",
       " 'ए ग ् न े स',\n",
       " 'ए ग ् न ् य ू',\n",
       " 'अ ग ् न ि क ा य न ा',\n",
       " 'अ ग ् न ि द े व',\n",
       " 'ए ग ् न ि ए ज ़ क ा',\n",
       " 'अ ग ् न ि ह ो त ् र',\n",
       " 'अ ग ् न ि ह ो त ् र ी',\n",
       " 'अ ग ् न ि म ा ं ड ् य ा',\n",
       " 'अ ग ् न ि म ि त ् र',\n",
       " 'अ ग ् न ि म ि त ् र ा',\n",
       " 'अ ग ् न ि प ु र ा ण',\n",
       " 'अ ग ् न ि',\n",
       " 'अ ग ो ग ो',\n",
       " 'अ ग ो ं ड ा',\n",
       " 'ए ग न ी',\n",
       " 'अ ग ू र न ा थ',\n",
       " 'अ ग प',\n",
       " 'ए ज ी प ी',\n",
       " 'अ ग ् र ब ा न ा',\n",
       " 'अ ग ् र ब ा ण',\n",
       " 'अ ग ् र ब ा न',\n",
       " 'अ ग ् र ह म',\n",
       " 'अ ग ् र ह र म',\n",
       " 'अ ग ् र ह ा र म',\n",
       " 'अ ग ् र ा ह र म',\n",
       " 'अ ग ् र ह ा र',\n",
       " 'अ ग ् र ह र ि',\n",
       " 'अ ग ् र ह ा य न ा',\n",
       " 'अ ग ् र क े',\n",
       " 'अ ग ् र स े न',\n",
       " 'अ ग ् र व ा न',\n",
       " 'अ ग ् र व ा ल',\n",
       " 'आ ग र ा',\n",
       " 'अ ग ् र ी ग े ट ो र',\n",
       " 'अ ग ् र ी म े न ् ट ् स',\n",
       " 'अ ग ् र ी म े ं ट',\n",
       " 'अ ग ् र ी म',\n",
       " 'अ ग ् र ी',\n",
       " 'ए ग ् र े स ि व',\n",
       " 'अ ग ् र े',\n",
       " 'ए ग ् र े',\n",
       " 'ए ग ् र ि क ल ् च र ल',\n",
       " 'ए ग ् र ी क ल ् च र ल',\n",
       " 'ए ग ् र ी क ल ् च र',\n",
       " 'अ ग ् र ी म े ट',\n",
       " 'ए ग ् र ि न े ट',\n",
       " 'अ ग ् र ी',\n",
       " 'ए ग ् र ो म े ट',\n",
       " 'ए ग ् र ो ट ि स',\n",
       " 'अ ग ु आ द ा',\n",
       " 'अ ग ु आ स',\n",
       " 'अ ग ु द ा थ',\n",
       " 'अ ग ु ड ा',\n",
       " 'अ ग ु म ् ब े',\n",
       " 'अ ग ं ग',\n",
       " 'अ ग ् व ा न प ु र',\n",
       " 'अ ह द प न े',\n",
       " 'अ ह ल ् य ा',\n",
       " 'अ ह ल',\n",
       " 'अ ह म द ा ब ा द',\n",
       " 'अ ह म द ी',\n",
       " 'अ ह म द ा ब ा द',\n",
       " 'अ ह म क ा र ा',\n",
       " 'अ ह ा न ा',\n",
       " 'अ ह न क ा र',\n",
       " 'आ ह ा र',\n",
       " 'अ ह ा र',\n",
       " 'आ ह र',\n",
       " 'अ ह ा त ् म ा',\n",
       " 'अ ह व ल',\n",
       " 'अ ह ा',\n",
       " 'आ ह ब ि ब ु आ र',\n",
       " 'अ ह ी र',\n",
       " 'अ ह म द ा ब ा द',\n",
       " 'अ ह ि ल े श ् व र',\n",
       " 'अ ह ि ल ् य ा ब ा ई',\n",
       " 'अ ह ि ल ् य ा',\n",
       " 'अ ह ि म ् स ा',\n",
       " 'अ ह ि र ् स',\n",
       " 'अ ह ि र',\n",
       " 'अ ह ि स ् त ा',\n",
       " 'अ ह ि त ा य ु',\n",
       " 'अ ह क म',\n",
       " 'अ ह ल ा व त',\n",
       " 'अ ह ल म द',\n",
       " 'अ ह ल ु व ा ल ि य ा',\n",
       " 'आ ह ल ु व ा ल ि य ा',\n",
       " 'आ ह ल ू व ा ल ि य ा',\n",
       " 'अ ह ल',\n",
       " 'अ ह म द ा ब ा द',\n",
       " 'अ ह म द ी न े ज ा द',\n",
       " 'अ ह म द ी न े ज ़ ा द',\n",
       " 'अ ह म द ि य ा',\n",
       " 'अ ह म द प ु र',\n",
       " 'अ ह म द',\n",
       " 'अ ह म ा द',\n",
       " 'अ ह म द ा ब ा द',\n",
       " 'अ ह म द ा ब ा र',\n",
       " 'अ ह म द ि य ा',\n",
       " 'अ ह म द ि य ा स',\n",
       " 'अ ह म द न ग र',\n",
       " 'अ ह म द प ु र',\n",
       " 'अ ह म द',\n",
       " 'आ ह म द',\n",
       " 'अ ह म त',\n",
       " 'अ ह ो म ् स',\n",
       " 'अ ह ो म',\n",
       " 'अ ह ो न न',\n",
       " 'अ ह ो न े न ा',\n",
       " 'अ ह ो न े न',\n",
       " 'अ ह क ़ ा फ ़',\n",
       " 'अ ह र म',\n",
       " 'अ ह र ा र',\n",
       " 'अ ह र ौ र ा',\n",
       " 'अ ह र े न ् स',\n",
       " 'ए ह स ा स',\n",
       " 'ए ह स ा न',\n",
       " 'अ ह स ् व थ ा म ा',\n",
       " 'अ ह त ि स ा र ी',\n",
       " 'अ ह ू ज ा',\n",
       " 'आ ह ु ज ा',\n",
       " 'आ ह ू ज ा',\n",
       " 'अ ह ु र ा',\n",
       " 'अ ह व त ् थ ा म ा',\n",
       " 'आ ई आ ई प ा ल',\n",
       " 'ए आ ई ए ए स',\n",
       " 'ए आ ई ए ट ी ए स ए ल',\n",
       " 'ए आ ई ब ी ए म ए स',\n",
       " 'ए आ ई ब ी प ी',\n",
       " 'ए आ इ स ी स ी',\n",
       " 'आ इ च ी',\n",
       " 'ए आ ई स ी ए ल',\n",
       " 'ए आ ई स ी ट ी ई',\n",
       " 'ए आ ई स ी',\n",
       " 'ए ड े ड',\n",
       " 'ए ड ी',\n",
       " 'ए ड ् स',\n",
       " 'ए आ ई ई ए स ए ल',\n",
       " 'ए आ ई ए फ',\n",
       " 'आ ई ह ो ल',\n",
       " 'ए ह ो ल',\n",
       " 'ए क ् य ा',\n",
       " 'ए ल ु र स',\n",
       " 'आ ई म ा ग',\n",
       " 'अ इ म ा क ़',\n",
       " 'ए म ी',\n",
       " 'ए म र',\n",
       " 'ए आ ई ए म ए ल',\n",
       " 'ए आ ई ए म ए म',\n",
       " 'ए म ् स',\n",
       " ...]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hinlis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize english and hindi Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 31\n",
      "English Max Length: 21\n",
      "Hindi Vocabulary Size: 69\n",
      "Hindi Max Length: 21\n"
     ]
    }
   ],
   "source": [
    "\n",
    "eng_tokenizer = create_tokenizer(englis)\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "eng_length = max_length(englis)\n",
    "\n",
    "\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)\n",
    "print('English Max Length: %d' % (eng_length))\n",
    "hin_tokenizer = create_tokenizer(hinlis)\n",
    "hin_vocab_size = len(hin_tokenizer.word_index) + 1\n",
    "hin_length = max_length(hinlis)\n",
    "print('Hindi Vocabulary Size: %d' % hin_vocab_size)\n",
    "print('Hindi Max Length: %d' % (hin_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eng_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import  to_categorical\n",
    "from numpy import array\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the sequence of the text and pad  that to max lenght pf the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sequences(tokenizer, length, lines):\n",
    "# integer encode sequences\n",
    "    X = tokenizer.texts_to_sequences(lines)\n",
    "    # pad sequences with 0 values\n",
    "    X = pad_sequences(X, maxlen=length, padding='post')\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the label into categorical from so that categorical cross entropy loss function on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode target sequence\n",
    "def encode_output(sequences, vocab_size):\n",
    "    ylist = list()\n",
    "    for sequence in sequences:\n",
    "        encoded = to_categorical(sequence, num_classes=vocab_size)\n",
    "        ylist.append(encoded)\n",
    "        y = array(ylist)\n",
    "    y = y.reshape(sequences.shape[0], sequences.shape[1], vocab_size)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Building using embedding layer LSTM unit with Repeat Vector layer and Time Distrbuted layer softmax as a activation function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(src_vocab, tar_vocab, src_timesteps, tar_timesteps, n_units):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(src_vocab, n_units, input_length=src_timesteps, mask_zero=True))\n",
    "    model.add(LSTM(n_units))\n",
    "    model.add(RepeatVector(tar_timesteps))\n",
    "    model.add(LSTM(n_units, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(tar_vocab, activation='softmax')))\n",
    "    return model\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare training and testing data and compile the model with categorical cross entropy loss and adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 31\n",
      "English Max Length: 21\n",
      "Hindi Vocabulary Size: 69\n",
      "Hindi Max Length: 21\n"
     ]
    }
   ],
   "source": [
    "\n",
    "eng_tokenizer = create_tokenizer(englis)\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "eng_length = max_length(englis)\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)\n",
    "print('English Max Length: %d' % (eng_length))\n",
    "\n",
    "hin_tokenizer = create_tokenizer(hinlis)\n",
    "hin_vocab_size = len(hin_tokenizer.word_index) + 1\n",
    "hin_length = max_length(hinlis)\n",
    "print('Hindi Vocabulary Size: %d' % hin_vocab_size)\n",
    "print('Hindi Max Length: %d' % (hin_length))\n",
    " \n",
    "# prepare training data\n",
    "trainX = encode_sequences(hin_tokenizer, eng_length, trainen)\n",
    "trainY = encode_sequences(eng_tokenizer,hin_length , trainhin)\n",
    "trainY = encode_output(trainY, hin_vocab_size)\n",
    "# prepare validation data\n",
    "testX = encode_sequences(hin_tokenizer, eng_length, testen)\n",
    "testY = encode_sequences(eng_tokenizer, hin_length, testhin)\n",
    "testY = encode_output(testY, hin_vocab_size)\n",
    " \n",
    "# define model\n",
    "model = define_model(eng_vocab_size, hin_vocab_size, eng_length, hin_length, 256)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model and store the weights in h5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5500 samples, validate on 1499 samples\n",
      "Epoch 1/150\n",
      " - 6s - loss: 0.5869 - acc: 1.0000 - val_loss: 0.1103 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11035, saving model to model.h5\n",
      "Epoch 2/150\n",
      " - 4s - loss: 0.0109 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.11035 to 0.00000, saving model to model.h5\n",
      "Epoch 3/150\n",
      " - 4s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00000\n",
      "Epoch 4/150\n",
      " - 4s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00000\n",
      "Epoch 5/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00000\n",
      "Epoch 6/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00000\n",
      "Epoch 7/150\n",
      " - 4s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00000\n",
      "Epoch 8/150\n",
      " - 4s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00000\n",
      "Epoch 9/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00000\n",
      "Epoch 10/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00000\n",
      "Epoch 11/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00000\n",
      "Epoch 12/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00000\n",
      "Epoch 13/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00000\n",
      "Epoch 14/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00000\n",
      "Epoch 15/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00000\n",
      "Epoch 16/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00000\n",
      "Epoch 17/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00000\n",
      "Epoch 18/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00000\n",
      "Epoch 19/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00000\n",
      "Epoch 20/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00000\n",
      "Epoch 21/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00000\n",
      "Epoch 22/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00000\n",
      "Epoch 23/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00000\n",
      "Epoch 24/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00000\n",
      "Epoch 25/150\n",
      " - 4s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00000\n",
      "Epoch 26/150\n",
      " - 4s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00000\n",
      "Epoch 27/150\n",
      " - 4s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00000\n",
      "Epoch 28/150\n",
      " - 4s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00000\n",
      "Epoch 29/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00000\n",
      "Epoch 30/150\n",
      " - 4s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00000\n",
      "Epoch 31/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00000\n",
      "Epoch 32/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00000\n",
      "Epoch 33/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00000\n",
      "Epoch 34/150\n",
      " - 4s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00000\n",
      "Epoch 35/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.00000\n",
      "Epoch 36/150\n",
      " - 4s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.00000\n",
      "Epoch 37/150\n",
      " - 4s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.00000\n",
      "Epoch 38/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00000\n",
      "Epoch 39/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.00000\n",
      "Epoch 40/150\n",
      " - 4s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00000\n",
      "Epoch 41/150\n",
      " - 4s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.00000\n",
      "Epoch 42/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.00000\n",
      "Epoch 43/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.00000\n",
      "Epoch 44/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.00000\n",
      "Epoch 45/150\n",
      " - 4s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.00000\n",
      "Epoch 46/150\n",
      " - 4s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.00000\n",
      "Epoch 47/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.00000\n",
      "Epoch 48/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.00000\n",
      "Epoch 49/150\n",
      " - 4s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.00000\n",
      "Epoch 50/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.00000\n",
      "Epoch 51/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.00000\n",
      "Epoch 52/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.00000\n",
      "Epoch 53/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.00000\n",
      "Epoch 54/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.00000\n",
      "Epoch 55/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.00000\n",
      "Epoch 56/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.00000\n",
      "Epoch 57/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.00000\n",
      "Epoch 58/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.00000\n",
      "Epoch 59/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.00000\n",
      "Epoch 60/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.00000\n",
      "Epoch 61/150\n",
      " - 4s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.00000\n",
      "Epoch 62/150\n",
      " - 4s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.00000\n",
      "Epoch 63/150\n",
      " - 4s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.00000\n",
      "Epoch 64/150\n",
      " - 4s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.00000\n",
      "Epoch 65/150\n",
      " - 4s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.00000\n",
      "Epoch 66/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.00000\n",
      "Epoch 67/150\n",
      " - 4s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.00000\n",
      "Epoch 68/150\n",
      " - 4s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.00000\n",
      "Epoch 69/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.00000\n",
      "Epoch 70/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.00000\n",
      "Epoch 71/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.00000\n",
      "Epoch 72/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.00000\n",
      "Epoch 73/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.00000\n",
      "Epoch 74/150\n",
      " - 4s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.00000\n",
      "Epoch 75/150\n",
      " - 4s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.00000\n",
      "Epoch 76/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.00000\n",
      "Epoch 77/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.00000\n",
      "Epoch 78/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.00000\n",
      "Epoch 79/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.00000\n",
      "Epoch 80/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.00000\n",
      "Epoch 81/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.00000\n",
      "Epoch 82/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.00000\n",
      "Epoch 83/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.00000\n",
      "Epoch 84/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.00000\n",
      "Epoch 85/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.00000\n",
      "Epoch 86/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.00000\n",
      "Epoch 87/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.00000\n",
      "Epoch 88/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.00000\n",
      "Epoch 89/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.00000\n",
      "Epoch 90/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.00000\n",
      "Epoch 91/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.00000\n",
      "Epoch 92/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.00000\n",
      "Epoch 93/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.00000\n",
      "Epoch 94/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.00000\n",
      "Epoch 95/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.00000\n",
      "Epoch 96/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.00000\n",
      "Epoch 97/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.00000\n",
      "Epoch 98/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.00000\n",
      "Epoch 99/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.00000\n",
      "Epoch 100/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.00000\n",
      "Epoch 101/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.00000\n",
      "Epoch 102/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.00000\n",
      "Epoch 103/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.00000\n",
      "Epoch 104/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.00000\n",
      "Epoch 105/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.00000\n",
      "Epoch 106/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.00000\n",
      "Epoch 107/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.00000\n",
      "Epoch 108/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.00000\n",
      "Epoch 109/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.00000\n",
      "Epoch 110/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.00000\n",
      "Epoch 111/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.00000\n",
      "Epoch 112/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.00000\n",
      "Epoch 113/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00113: val_loss did not improve from 0.00000\n",
      "Epoch 114/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.00000\n",
      "Epoch 115/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.00000\n",
      "Epoch 116/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.00000\n",
      "Epoch 117/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.00000\n",
      "Epoch 118/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.00000\n",
      "Epoch 119/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.00000\n",
      "Epoch 120/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.00000\n",
      "Epoch 121/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.00000\n",
      "Epoch 122/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.00000\n",
      "Epoch 123/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.00000\n",
      "Epoch 124/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.00000\n",
      "Epoch 125/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.00000\n",
      "Epoch 126/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.00000\n",
      "Epoch 127/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.00000\n",
      "Epoch 128/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.00000\n",
      "Epoch 129/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.00000\n",
      "Epoch 130/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.00000\n",
      "Epoch 131/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.00000\n",
      "Epoch 132/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.00000\n",
      "Epoch 133/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.00000\n",
      "Epoch 134/150\n",
      " - 4s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.00000\n",
      "Epoch 135/150\n",
      " - 4s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.00000\n",
      "Epoch 136/150\n",
      " - 4s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.00000\n",
      "Epoch 137/150\n",
      " - 4s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.00000\n",
      "Epoch 138/150\n",
      " - 4s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.00000\n",
      "Epoch 139/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.00000\n",
      "Epoch 140/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.00000\n",
      "Epoch 141/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.00000\n",
      "Epoch 142/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.00000\n",
      "Epoch 143/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.00000\n",
      "Epoch 144/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.00000\n",
      "Epoch 145/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.00000\n",
      "Epoch 146/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.00000\n",
      "Epoch 147/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.00000\n",
      "Epoch 148/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.00000\n",
      "Epoch 149/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.00000\n",
      "Epoch 150/150\n",
      " - 3s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 0.9999\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.00000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f88745f33c8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "#model.fit(trainX, trainY, epochs=150, batch_size=64, validation_data=(testX, testY), callbacks=[checkpoint], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(testX,testY,verbose=0)\n",
    "#print(testY[0])\n",
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy measure of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of this model on Test set is 0.999904698733889\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy of this model on Test set is\",score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 21, 256)           7936      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 21, 256)           525312    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 21, 69)            17733     \n",
      "=================================================================\n",
      "Total params: 1,076,293\n",
      "Trainable params: 1,076,293\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5><b>Future Improvement </b></font><br/>\n",
    "<font size=3>\n",
    "Currently from the learning curve I can say that  the model is getting overfitting the possible measure we can do improve the model\n",
    "<ol>\n",
    "  <li>Use drop for the regulization purpose</li>\n",
    "  <li>Add Noise to the dataset</li>\n",
    "  <li>Use Fast.ai api for the embedding of Hindi and english words</li>\n",
    "  <li>Use GAN architecure with two categorical loss function (if we high volume of data)</li>\n",
    "  <li>Use advance BERT model to achive this task</li>\n",
    "  <li>Most obivous increase the training data</li>\n",
    "  <li>Use attention model only(if we high volume of data)</li>\n",
    "  \n",
    "</ol> \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
